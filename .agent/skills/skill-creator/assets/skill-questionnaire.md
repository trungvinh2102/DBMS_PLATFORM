# Skill Requirements Questionnaire

> **For Agent:** This is a BASE TEMPLATE. You MUST customize with domain-specific questions before giving to user.
>
> **For User:** Fill in this form to help define your skill requirements clearly.
> Delete examples and replace with your answers.

---

## Phase 1: Discovery (WHY & WHO)

### What specific problem needs to be solved?

<!-- Example: "I need a skill that helps write consistent unit tests for React components" -->

### Who will use this skill?

<!-- Options: agent, human, or both -->

### What triggers the need to create/upgrade this skill?

<!-- Example: "Current testing workflow is inconsistent across the team" -->

---

## Phase 2: Context (WHAT & WHERE)

### What is the specific domain?

<!-- Options: frontend, backend, devops, AI, blockchain, mobile, etc. -->

### What tech stack or frameworks are involved?

<!-- Example: "React, Jest, Testing Library, TypeScript" -->

### What constraints must be followed?

<!-- Example: "Must work with existing CI/CD pipeline, team of 5 developers" -->

---

## Phase 3: Scope (BOUNDARIES)

### What is IN scope?

<!-- List specific features/capabilities the skill MUST have -->

-
-
-

### What is OUT of scope?

<!-- List what the skill should NOT handle -->

-
-
-

### Upgrade type (for existing skills only)

<!-- Options: Minor Update / Major Upgrade / Restructure -->

### Dependencies with other skills/tools?

<!-- List any skills or tools this should integrate with -->

---

## Phase 4: Quality (STANDARDS)

### What level of expertise should this skill embody?

<!-- Options: junior, senior, expert (20+ years) -->

### Design Principle: Separation of Concerns

<!-- Reminder:
- Skill = Knowledge (Capabilities, Standards, Best Practices)
- Workflow = Process (Steps, Sequences, Lifecycles)
Do NOT ask for "Process" definitions here. Focus on "Knowledge".
-->

### Which best practices must be followed?

<!-- Example: "Follow Testing Trophy pattern, AAA structure for tests" -->

### What edge cases need to be handled?

<!-- List specific edge cases or error scenarios -->

-
-
- ***

## Phase 5: Validation (SUCCESS CRITERIA)

### What are the acceptance criteria?

<!-- List specific, measurable criteria for success -->

- [ ]
- [ ]
- [ ]

### How do we know the skill works correctly?

<!-- Example: "Successfully generates tests that pass CI, covers >80% of cases" -->

### What metrics measure improvement?

<!-- Example: "Time to write tests reduced by 50%, test coverage increased" -->

---

## Additional Notes

<!-- Any other context, examples, or references that would help -->
